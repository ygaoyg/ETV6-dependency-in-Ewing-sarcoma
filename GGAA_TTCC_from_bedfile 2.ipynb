{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.encodeproject.org/files/GRCh38_EBV.chrom.sizes/@@download/GRCh38_EBV.chrom.sizes.tsv\n",
    "http://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.fa.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, threshold):\n",
    "    \"\"\"\n",
    "    Group consequtive GGAA or TTCCs into one. Modify the threshold to group interspersed GGAAs as 1 unit\n",
    "    \"\"\"\n",
    "    prev = None\n",
    "    group = []\n",
    "    megagroup = []\n",
    "    for j,item in enumerate(iterable):\n",
    "        if not prev or item - prev <= threshold:\n",
    "            group.append(item)\n",
    "        else:\n",
    "            megagroup.append(group)\n",
    "            group = [item]\n",
    "        prev = item\n",
    "    if group:\n",
    "        megagroup.append(group)\n",
    "    cluster_lengths = [len(i) for i in megagroup]\n",
    "    return cluster_lengths\n",
    "\n",
    "def str_find_and_merge(one_str_seq,pattern='GGAA',threshold=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Same as above but works for toy examples of strings\n",
    "    e.g. str_find_and_merge('GGAATGGAA') will return array([5]), [2]\n",
    "    \"\"\"\n",
    "    ttcc_idx = [m.start() for m in re.finditer(pattern, one_str_seq)]\n",
    "    res = grouper(ttcc_idx, threshold)\n",
    "    distances = np.ediff1d(ttcc_idx)\n",
    "    return (distances,res)\n",
    "\n",
    "def get_line_number(filepath):\n",
    "    file = open(filepath, \"r\") # open \n",
    "    nonempty_lines = [line.strip(\"\\n\") for line in file if line != \"\\n\"] # get lines\n",
    "    line_count = len(nonempty_lines) # count lines\n",
    "    file.close() # close file\n",
    "    return line_count\n",
    "\n",
    "def get_ggaa_ttcc_from(bedfile, fastafile, output_dir):\n",
    "    \"\"\" \n",
    "    Process a bedfile dataset\n",
    "    \"\"\"\n",
    "    # initialize an empty dictionary\n",
    "    dataset_name = fastafile.split('/')[-1].split('.fa')[0]\n",
    "    seq=[]\n",
    "    for line in open(fastafile):\n",
    "        if line[0] != '>':\n",
    "            seq.append(line.rstrip().upper())\n",
    "\n",
    "    bedlines=[]\n",
    "    res = {}\n",
    "    for line in open(bedfile):\n",
    "        bedlines.append(line.split('\\t'))\n",
    "    for i in range(len(bedlines[0])):\n",
    "        if i ==0:\n",
    "            colname = 'chromosome'\n",
    "        elif i ==1:\n",
    "            colname = \"start\"\n",
    "        elif i == 2:\n",
    "            colname = 'end'\n",
    "        else:\n",
    "            colname = 'bedfile col{}'.format(i+1)\n",
    "        res[colname] = [bedrow[i] for bedrow in bedlines]\n",
    "\n",
    "    res['1'] = []\n",
    "    res['2'] = []\n",
    "    res['3'] = []\n",
    "    res['>4'] = []\n",
    "   \n",
    "    \n",
    "    # per sequence or peak or bed range\n",
    "    for s in seq: \n",
    "        ggaa_lengths = np.array(str_find_and_merge(s, 'GGAA', 4)[1]) # get GGAA occurances\n",
    "        ttcc_lengths = np.array(str_find_and_merge(s, 'TTCC', 4)[1]) # get TTCC occurances\n",
    "        res['1'].append(np.sum(ggaa_lengths==1)+np.sum(ttcc_lengths==1)) # number of singles\n",
    "        res['2'].append(np.sum(ggaa_lengths==2)+np.sum(ttcc_lengths==2)) # doubles\n",
    "        res['3'].append(np.sum(ggaa_lengths==3)+np.sum(ttcc_lengths==3)) # triples\n",
    "        res['>4'].append(np.sum(ggaa_lengths==4)+np.sum(ttcc_lengths>4)) # microsatelites\n",
    "    df = pd.DataFrame(res) # define a dataframe\n",
    "    df.to_csv(os.path.join(output_dir, '{}_from_fa_ggaa_ttcc.csv'.format(dataset_name))) # save as a file\n",
    "    print(\"Completed analysis of \"+bedfile)\n",
    "    \n",
    "def make_chrom_size_bed(chromsizes_path, output_dir):\n",
    "    chrombed_path = os.path.join(output_dir, 'chromsizes.bed')\n",
    "    chromsizes_df = pd.read_csv(chromsizes_path, sep='\\t', header=None)\n",
    "    chrom_bed = pd.DataFrame(zip(chromsizes_df[0].values,\n",
    "                             [1 for i in range(len(chromsizes_df[1].values))],\n",
    "                             chromsizes_df[1].values))\n",
    "    chrom_bed.to_csv(chrombed_path, header=None, sep='\\t', index=None)\n",
    "    return chrombed_path\n",
    "    \n",
    "def check_file_sizes(fasta, bed):\n",
    "    # check that bed and fa are the same size\n",
    "    fa_size = get_line_number(fasta)\n",
    "    bed_size = get_line_number(bed)\n",
    "    if fa_size!=bed_size*2:\n",
    "        return False\n",
    "    else:\n",
    "#         print('BED correctly converted to FASTA')\n",
    "        return True\n",
    "        \n",
    "def bed_to_fa(bedfile,chrombed_path, genome_file,output_path):\n",
    "    # filter the bedfile ranges beyong the chromosome size\n",
    "    prefix = bedfile.split('.bed')[0]\n",
    "    print(prefix)\n",
    "    output_bed = prefix+'_filtered.bed'\n",
    "    scp_cmd = 'scp {} {}'.format(bedfile, output_bed)\n",
    "                                                                            \n",
    "    subprocess.call(scp_cmd, shell=True)\n",
    "    \n",
    "    \n",
    "        # convert to fasta\n",
    "    output_fasta = prefix+'.fa'\n",
    "\n",
    "    fa_cmd = 'bedtools getfasta -s -fi {} -bed {} -fo {}'.format(genome_file, \n",
    "                                                                              output_bed,\n",
    "                                                                             output_fasta)\n",
    "    subprocess.call(fa_cmd, shell=True)\n",
    "    if not check_file_sizes(output_fasta, output_bed):\n",
    "        \n",
    "        filter_cmd = 'bedtools intersect -f 1 -wa -a {} -b {} > {}'.format(bedfile,\n",
    "                                                                          chrombed_path,\n",
    "                                                                          output_bed)\n",
    "        subprocess.call(filter_cmd, shell=True)\n",
    "        output_fasta = output_bed.split('.bed')[0]+'.fa'\n",
    "\n",
    "        fa_cmd = 'bedtools getfasta -s -fi {} -bed {} -fo {}'.format(genome_file, \n",
    "                                                                     output_bed,\n",
    "                                                                    output_fasta)\n",
    "        subprocess.call(fa_cmd, shell=True)\n",
    "    assert check_file_sizes(output_fasta, output_bed), \"FASTA conversion failed!\"\n",
    "    print(\"{} converted to FASTA\".format(bedfile))\n",
    "    return (output_bed, output_fasta)\n",
    "\n",
    "\n",
    "def make_dir(output_path):\n",
    "    if not os.path.isdir(output_path):\n",
    "        print(\"Making directory for results\")\n",
    "        os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes = 'GRCh38_EBV.chrom.sizes.tsv' # file path with chromosome sizes\n",
    "output_dir = 'output' # path where the output will be saved\n",
    "genome_file = 'hg38.fa' # genome path\n",
    "# list of bed files to process, can be just 1 as well, but need to put in a list, e.g. [file.bed]\n",
    "bedfile_list = ['GT.bed']\n",
    "make_dir(output_dir) # create output dir if not present already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT\n",
      "GT.bed converted to FASTA\n",
      "Completed analysis of GT_filtered.bed\n"
     ]
    }
   ],
   "source": [
    "chrombed_path = make_chrom_size_bed(chromsizes, output_dir) # create a bed file out of the chromosome sizes file\n",
    "for bedfile in bedfile_list: # per bed file\n",
    "    output_bed, output_fasta = bed_to_fa(bedfile, chrombed_path, genome_file, output_dir) # convert to FASTA\n",
    "    get_ggaa_ttcc_from(output_bed, output_fasta, output_dir) # compute summary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
